## sedona（一） ##

### 1)依赖包引入 ###


	<!--spark hadoop-->
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.version}</artifactId>
      <version>${spark.version}</version>
      <!--      <scope>provided</scope>-->
    </dependency>

    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_2.11</artifactId>
      <version>${spark.version}</version>
    </dependency>
	<!--    sedona-->
    <dependency>
      <groupId>org.apache.sedona</groupId>
      <artifactId>sedona-core-2.4_2.11</artifactId>
      <version>1.0.0-incubating</version>
    </dependency>
    <dependency>
      <groupId>org.apache.sedona</groupId>
      <artifactId>sedona-sql-2.4_2.11</artifactId>
      <version>1.0.0-incubating</version>
    </dependency>
    <dependency>
      <groupId>org.apache.sedona</groupId>
      <artifactId>sedona-viz-2.4_2.11</artifactId>
      <version>1.0.0-incubating</version>
    </dependency>

	<!--    jts-->
    <dependency>
      <groupId>org.locationtech.jts</groupId>
      <artifactId>jts-core</artifactId>
      <version>1.18.0</version>
    </dependency>

    <dependency>
      <groupId>org.wololo</groupId>
      <artifactId>jts2geojson</artifactId>
      <version>0.14.3</version>
    </dependency>

	<!--geotools-->
    <!-- https://mvnrepository.com/artifact/org.geotools/gt-main -->
    <dependency>
      <groupId>org.geotools</groupId>
      <artifactId>gt-main</artifactId>
      <version>24.0</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/org.geotools/gt-referencing -->
    <dependency>
      <groupId>org.geotools</groupId>
      <artifactId>gt-referencing</artifactId>
      <version>24.0</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/org.geotools/gt-epsg-hsql -->
    <dependency>
      <groupId>org.geotools</groupId>
      <artifactId>gt-epsg-hsql</artifactId>
      <version>24.0</version>
    </dependency>


sedona没有引入jts和geotools，需要自己添加

sedona支持scala2.11+spark2.4，scala2.12+spark2.4/spark3.0


### 2) SparkContext初始化 ###
	val conf = new SparkConf()
    conf.setAppName("SedonaRunnableExample") // Change this to a proper name
    conf.setMaster("local[*]") // Delete this if run in cluster mode
    conf.set("spark.serializer", classOf[KryoSerializer].getName) // org.apache.spark.serializer.KryoSerializer
    conf.set("spark.kryo.registrator", classOf[SedonaKryoRegistrator].getName) // org.apache.sedona.core.serde.SedonaKryoRegistrator
	System.setProperty("sedona.global.charset", "utf8")
    val sc = new SparkContext(conf)

### 3)shapefile读取 ###
	val shapefileInputLocation="D:\\data\\shapefile"
    val spatialRDD = ShapefileReader.readToGeometryRDD(sc, shapefileInputLocation)
   
### 4)txt输出 ###

	spatialRDD.rawSpatialRDD.saveAsTextFile("file:///F:\\data\\bigdata\\output\\u3") 

### 问题 ###

1读shapefile异常，

	Exception in thread "main" java.lang.RuntimeException: Error while running command to get file permissions : java.io.IOException: (null) entry in command string: null ls -F D:\data\shapefile\a.cpg

解决：安装hadoop环境，并把winutils和hadoop.dll复制到C:\Windows\System32

https://github.com/steveloughran/winutils

同时在idea调试配置添加环境变量：HADOOP_HOME=D:\hadoop


### 参考 ###

http://sedona.apache.org/tutorial/rdd/

	